{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read orginal books to strings\n",
    "f = open(\"Dick Philip. Ubik.txt\",\"r\")\n",
    "ubik = f.read()\n",
    "f = open(\"Dick Philip. Valis.txt\",\"r\")\n",
    "valis = f.read()\n",
    "f = open(\"Dick Philip. A Maze of Death.txt\",\"r\")\n",
    "maze = f.read()\n",
    "f = open(\"Dick Philip. Radio Free Albemuth.txt\",\"r\")\n",
    "radio = f.read()\n",
    "f = open(\"Dick Philip. The Three Stigmata of Palmer Eldritch.txt\",\"r\")\n",
    "palmer = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corpus from books\n",
    "# Concatuate in one list\n",
    "\n",
    "def books_to_corpus(books):\n",
    "    corpus = list()\n",
    "    for i in books:\n",
    "        # Tokenize the article: tokens\n",
    "        tokens = word_tokenize(i)\n",
    "        # Convert the tokens into lowercase: lower_tokens\n",
    "        lower_tokens = [t.lower() for t in tokens]\n",
    "        # Retain alphabetic words: alpha_only\n",
    "        alpha_only = [t for t in lower_tokens if t.isalpha()]\n",
    "        # Remove all stop words: no_stops\n",
    "        no_stops = [t for t in alpha_only if t not in stopwords.words('english')]\n",
    "        # Instantiate the WordNetLemmatizer\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        # Lemmatize all tokens into a new list: lemmatized\n",
    "        lemmatized = [wordnet_lemmatizer.lemmatize(t) for t in no_stops]\n",
    "        corpus.append(lemmatized) \n",
    "    return corpus\n",
    "\n",
    "titles = ['ubik', 'valis', 'maze', 'radio', 'palmer']\n",
    "corpus_dick = books_to_corpus([ubik, valis, maze, radio, palmer])\n",
    "\n",
    "dictofdick = dict(zip(titles, corpus_dick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dick Philip. Ubik 50 top words \n",
      "\n",
      "[('said', 1184), ('joe', 717), ('runciter', 467), ('one', 239), ('al', 204), ('know', 191), ('back', 181), ('u', 179), ('get', 163), ('time', 161), ('could', 160), ('like', 160), ('pat', 157), ('would', 156), ('thought', 149), ('chip', 132), ('asked', 130), ('way', 110), ('ubik', 106), ('right', 104), ('door', 104), ('room', 103), ('go', 103), ('see', 102), ('think', 96), ('denny', 96), ('made', 91), ('hand', 90), ('tell', 90), ('want', 90), ('moratorium', 90), ('going', 89), ('maybe', 88), ('ca', 86), ('make', 85), ('say', 84), ('jory', 84), ('new', 81), ('voice', 81), ('come', 81), ('got', 80), ('take', 80), ('ella', 77), ('face', 76), ('look', 75), ('two', 74), ('something', 74), ('hollis', 69), ('year', 64), ('girl', 64)] \n",
      "\n",
      "Dick Philip. Valis 50 top words \n",
      "\n",
      "[('said', 1109), ('fat', 979), ('kevin', 365), ('time', 307), ('one', 302), ('god', 288), ('could', 251), ('u', 243), ('would', 242), ('sherri', 194), ('know', 187), ('like', 157), ('say', 155), ('see', 138), ('back', 134), ('world', 133), ('two', 131), ('vali', 128), ('information', 128), ('life', 126), ('never', 120), ('mind', 120), ('way', 119), ('people', 119), ('go', 113), ('get', 109), ('day', 106), ('david', 106), ('linda', 104), ('gloria', 101), ('lampton', 100), ('universe', 96), ('thing', 95), ('form', 94), ('mini', 94), ('knew', 93), ('something', 90), ('thought', 88), ('going', 88), ('death', 86), ('man', 85), ('eric', 85), ('year', 81), ('sophia', 81), ('got', 80), ('right', 80), ('mean', 80), ('well', 79), ('cat', 79), ('nothing', 78)] \n",
      "\n",
      "Dick Philip. A Maze of Death 50 top words \n",
      "\n",
      "[('said', 1136), ('morley', 454), ('seth', 301), ('one', 234), ('belsnor', 221), ('know', 183), ('babble', 180), ('thought', 165), ('russell', 153), ('could', 150), ('like', 149), ('get', 148), ('u', 143), ('back', 142), ('would', 141), ('time', 135), ('see', 117), ('think', 113), ('thugg', 113), ('frazer', 108), ('maggie', 106), ('asked', 99), ('go', 98), ('want', 97), ('mary', 97), ('man', 90), ('maybe', 85), ('way', 85), ('say', 84), ('come', 84), ('right', 83), ('hand', 82), ('walsh', 79), ('saw', 79), ('susie', 79), ('away', 78), ('tallchief', 76), ('building', 73), ('made', 70), ('toward', 70), ('squib', 70), ('something', 66), ('felt', 66), ('never', 66), ('form', 65), ('ship', 64), ('last', 64), ('nothing', 64), ('thing', 63), ('yes', 63)] \n",
      "\n",
      "Dick Philip. Radio Free Albemuth 50 top words \n",
      "\n",
      "[('said', 1079), ('nicholas', 427), ('would', 306), ('could', 305), ('one', 275), ('time', 237), ('know', 233), ('like', 194), ('u', 186), ('sadassa', 139), ('fremont', 134), ('rachel', 131), ('see', 130), ('never', 126), ('way', 124), ('back', 122), ('life', 117), ('people', 116), ('vivian', 116), ('record', 115), ('thought', 113), ('get', 112), ('asked', 111), ('vali', 108), ('told', 106), ('two', 105), ('going', 105), ('knew', 104), ('aramchek', 104), ('think', 101), ('voice', 100), ('berkeley', 100), ('well', 100), ('satellite', 100), ('phil', 99), ('world', 98), ('go', 98), ('tell', 96), ('got', 93), ('say', 93), ('come', 92), ('right', 91), ('something', 91), ('still', 90), ('day', 89), ('friend', 88), ('nothing', 88), ('saw', 86), ('want', 85), ('good', 84)] \n",
      "\n",
      "Dick Philip. The Three Stigmata of Palmer Eldritch 50 top words \n",
      "\n",
      "[('said', 1019), ('leo', 397), ('barney', 394), ('eldritch', 335), ('one', 242), ('back', 224), ('know', 209), ('like', 201), ('would', 185), ('palmer', 184), ('could', 171), ('get', 170), ('time', 166), ('thought', 166), ('even', 160), ('mayerson', 153), ('going', 136), ('go', 129), ('see', 126), ('want', 121), ('got', 120), ('right', 114), ('way', 114), ('bulero', 109), ('something', 99), ('anne', 99), ('emily', 98), ('layout', 93), ('maybe', 90), ('un', 89), ('u', 89), ('make', 87), ('mean', 86), ('mar', 85), ('nothing', 83), ('hand', 83), ('eye', 82), ('new', 81), ('still', 81), ('man', 81), ('hnatt', 81), ('say', 80), ('ship', 80), ('come', 78), ('made', 77), ('think', 77), ('life', 76), ('miss', 75), ('fugate', 74), ('roni', 74)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import stopwords\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# Import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def bow(text, top):\n",
    "    # Create the bag-of-words: bow\n",
    "    bow = Counter(text)\n",
    "    # Print most common tokens\n",
    "    return bow.most_common(top)\n",
    "\n",
    "print('Dick Philip. Ubik 50 top words \\n')\n",
    "print(bow(dictofdick['ubik'], 50), '\\n')\n",
    "print('Dick Philip. Valis 50 top words \\n')\n",
    "print(bow(dictofdick['valis'], 50), '\\n')\n",
    "print('Dick Philip. A Maze of Death 50 top words \\n')\n",
    "print(bow(dictofdick['maze'], 50), '\\n')\n",
    "print('Dick Philip. Radio Free Albemuth 50 top words \\n')\n",
    "print(bow(dictofdick['radio'], 50), '\\n')\n",
    "print('Dick Philip. The Three Stigmata of Palmer Eldritch 50 top words \\n')\n",
    "print(bow(dictofdick['palmer'], 50), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 1), (2, 8), (3, 1), (4, 1), (5, 1), (6, 16), (7, 28), (8, 1), (9, 6)]\n"
     ]
    }
   ],
   "source": [
    "# Import Dictionary\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a Dictionary from the articles: dictionary\n",
    "dictionary = Dictionary(list(dictofdick.values()))\n",
    "\n",
    "# Create a MmCorpus: corpus\n",
    "dick_corpus = [dictionary.doc2bow(article) for article in list(dictofdick.values())]\n",
    "\n",
    "# Print the first 10 word ids with their frequency counts from the first document, Ubik\n",
    "print(dick_corpus[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dick Philip. Ubik 50 top frequent words using Gensim \n",
      "\n",
      "said 5527\n",
      "one 1292\n",
      "could 1037\n",
      "would 1030\n",
      "time 1006\n",
      "know 1003\n",
      "fat 992\n",
      "like 861\n",
      "u 840\n",
      "back 803\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "# Save the fifth document, Ubik\n",
    "ubik_gensim = dick_corpus[0]\n",
    "\n",
    "def print_words_freq(book, corpus, dictionary, top):\n",
    "    # Sort the doc for frequency: bow_doc\n",
    "    bow_doc = sorted(book, key=lambda w: w[1], reverse=True)\n",
    "    # Print the top 5 words of the document alongside the count\n",
    "#     for word_id, word_count in bow_doc[:5]:\n",
    "#         print(dictionary.get(word_id), word_count)\n",
    "    # Create the defaultdict: total_word_count\n",
    "    total_word_count = defaultdict(int)\n",
    "    for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
    "        total_word_count[word_id] += word_count\n",
    "    # Create a sorted list from the defaultdict: sorted_word_count\n",
    "    sorted_word_count = sorted(total_word_count.items(), key=lambda w: w[1], reverse=True) \n",
    "    # Print the top 5 words across all documents alongside the count\n",
    "    for word_id, word_count in sorted_word_count[:top]:\n",
    "        print(dictionary.get(word_id), word_count)\n",
    "        \n",
    "print('Dick Philip. Ubik 50 top frequent words using Gensim without tfidf \\n')\n",
    "print_words_freq(ubik_gensim, dick_corpus, dictionary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dick Philip. Ubik 15 top frequent words with tdidf \n",
      "\n",
      "runciter 0.683\n",
      "joe 0.597\n",
      "denny 0.1404\n",
      "moratorium 0.1316\n",
      "jory 0.1228\n",
      "hollis 0.1009\n",
      "wendy 0.0892\n",
      "ubik 0.0883\n",
      "inertials 0.079\n",
      "hammond 0.076\n",
      "vogelsang 0.0673\n",
      "ella 0.0641\n",
      "ashwood 0.0629\n",
      "chip 0.0613\n",
      "conley 0.06\n",
      "\n",
      "Dick Philip. Valis 15 top frequent words with tdidf\n",
      "\n",
      "kevin 0.7057\n",
      "sherri 0.3751\n",
      "gloria 0.1953\n",
      "lampton 0.1933\n",
      "mini 0.1817\n",
      "sophia 0.1566\n",
      "vali 0.1409\n",
      "horselover 0.1353\n",
      "david 0.1167\n",
      "linda 0.1145\n",
      "zebra 0.1025\n",
      "eric 0.0936\n",
      "maurice 0.0909\n",
      "fremount 0.0889\n",
      "plasmate 0.0812\n",
      "\n",
      "Dick Philip. A Maze of Death 15 top frequent words with tdidf\n",
      "\n",
      "morley 0.7029\n",
      "belsnor 0.3422\n",
      "babble 0.2787\n",
      "seth 0.2653\n",
      "thugg 0.175\n",
      "frazer 0.1672\n",
      "maggie 0.1641\n",
      "russell 0.1349\n",
      "susie 0.1223\n",
      "walsh 0.1223\n",
      "tallchief 0.1177\n",
      "squib 0.1084\n",
      "wade 0.0929\n",
      "noser 0.0774\n",
      "betty 0.0681\n",
      "\n",
      "Dick Philip. Radio Free Albemuth 15 top frequent words with tdidf\n",
      "\n",
      "nicholas 0.6086\n",
      "fremont 0.3354\n",
      "rachel 0.3279\n",
      "vivian 0.2904\n",
      "aramchek 0.2603\n",
      "sadassa 0.1981\n",
      "vali 0.1539\n",
      "phil 0.1411\n",
      "kaplan 0.1126\n",
      "progressive 0.1101\n",
      "silvia 0.1076\n",
      "fap 0.1001\n",
      "brady 0.0912\n",
      "nick 0.0901\n",
      "berkeley 0.0795\n",
      "\n",
      "Dick Philip. The Three Stigmata of Palmer Eldritch 15 top frequent words with tdidf\n",
      "\n",
      "leo 0.5908\n",
      "barney 0.5864\n",
      "mayerson 0.2277\n",
      "bulero 0.1622\n",
      "eldritch 0.1582\n",
      "anne 0.1473\n",
      "emily 0.1459\n",
      "un 0.1325\n",
      "hnatt 0.1206\n",
      "fugate 0.1101\n",
      "hovel 0.1101\n",
      "roni 0.1101\n",
      "schein 0.0908\n",
      "palmer 0.0869\n",
      "layout 0.0788\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfModel\n",
    "from gensim.models.tfidfmodel import TfidfModel \n",
    "\n",
    "def print_tfidf_freq(book, corpus, dictionary, top = 10, order = True):\n",
    "\n",
    "    # Create a new TfidfModel using the corpus: tfidf\n",
    "    tfidf = TfidfModel(corpus)\n",
    "\n",
    "    # Calculate the tfidf weights of doc: tfidf_weights\n",
    "    tfidf_weights = tfidf[book]\n",
    "\n",
    "    # # Print the first five weights\n",
    "    # print(tfidf_weights[:5])\n",
    "\n",
    "    # Sort the weights from highest to lowest: sorted_tfidf_weights\n",
    "    sorted_tfidf_weights = sorted(tfidf_weights, key=lambda w: w[1], reverse=order)\n",
    "    \n",
    "    \n",
    "    # Print the top 5 weighted words\n",
    "    for term_id, weight in sorted_tfidf_weights[:top]:\n",
    "        print(dictionary.get(term_id), round(weight,4))\n",
    "\n",
    "print('Dick Philip. Ubik 15 top frequent words with tfidf \\n')\n",
    "print_tfidf_freq(dick_corpus[0], dick_corpus, dictionary, 15)\n",
    "print('\\nDick Philip. Valis 15 top frequent words with tfidf\\n')\n",
    "print_tfidf_freq(dick_corpus[1], dick_corpus, dictionary, 15)\n",
    "print('\\nDick Philip. A Maze of Death 15 top frequent words with tfidf\\n')\n",
    "print_tfidf_freq(dick_corpus[2], dick_corpus, dictionary, 15)\n",
    "print('\\nDick Philip. Radio Free Albemuth 15 top frequent words with tfidf\\n')\n",
    "print_tfidf_freq(dick_corpus[3], dick_corpus, dictionary, 15)\n",
    "print('\\nDick Philip. The Three Stigmata of Palmer Eldritch 15 top frequent words with tfidf\\n')\n",
    "print_tfidf_freq(dick_corpus[4], dick_corpus, dictionary, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dick Philip. Ubik 15 top infrequent words with tdidf \n",
      "\n",
      "abstract 0.0002\n",
      "admittedly 0.0002\n",
      "affair 0.0002\n",
      "affect 0.0002\n",
      "aimed 0.0002\n",
      "alertly 0.0002\n",
      "allow 0.0002\n",
      "america 0.0002\n",
      "amuse 0.0002\n",
      "amused 0.0002\n",
      "amusement 0.0002\n",
      "angrily 0.0002\n",
      "animosity 0.0002\n",
      "apartment 0.0002\n",
      "appeal 0.0002\n",
      "\n",
      "Dick Philip. Valis 15 top infrequent words with tdidf\n",
      "\n",
      "accustomed 0.0003\n",
      "admittedly 0.0003\n",
      "afford 0.0003\n",
      "al 0.0003\n",
      "alertly 0.0003\n",
      "amuse 0.0003\n",
      "amusement 0.0003\n",
      "animosity 0.0003\n",
      "appeal 0.0003\n",
      "arrest 0.0003\n",
      "aside 0.0003\n",
      "assassin 0.0003\n",
      "attorney 0.0003\n",
      "bait 0.0003\n",
      "beamed 0.0003\n",
      "\n",
      "Dick Philip. A Maze of Death 15 top infrequent words with tdidf\n",
      "\n",
      "abstract 0.0002\n",
      "aching 0.0002\n",
      "admire 0.0002\n",
      "aid 0.0002\n",
      "aimed 0.0002\n",
      "alertly 0.0002\n",
      "america 0.0002\n",
      "amuse 0.0002\n",
      "amused 0.0002\n",
      "appalled 0.0002\n",
      "artifact 0.0002\n",
      "ascended 0.0002\n",
      "augmented 0.0002\n",
      "avoid 0.0002\n",
      "awaken 0.0002\n",
      "\n",
      "Dick Philip. Radio Free Albemuth 15 top infrequent words with tdidf\n",
      "\n",
      "accustomed 0.0003\n",
      "aching 0.0003\n",
      "adequate 0.0003\n",
      "admire 0.0003\n",
      "afford 0.0003\n",
      "al 0.0003\n",
      "animosity 0.0003\n",
      "approval 0.0003\n",
      "arrival 0.0003\n",
      "ascended 0.0003\n",
      "assassin 0.0003\n",
      "augmented 0.0003\n",
      "bait 0.0003\n",
      "bear 0.0003\n",
      "belt 0.0003\n",
      "\n",
      "Dick Philip. The Three Stigmata of Palmer Eldritch 15 top infrequent words with tdidf\n",
      "\n",
      "admire 0.0002\n",
      "aimed 0.0002\n",
      "al 0.0002\n",
      "alleged 0.0002\n",
      "amuse 0.0002\n",
      "amusement 0.0002\n",
      "animosity 0.0002\n",
      "apartment 0.0002\n",
      "appalled 0.0002\n",
      "appointment 0.0002\n",
      "arrest 0.0002\n",
      "ascended 0.0002\n",
      "assassin 0.0002\n",
      "attorney 0.0002\n",
      "augmented 0.0002\n"
     ]
    }
   ],
   "source": [
    "print('Dick Philip. Ubik 15 top infrequent words with tdidf \\n')\n",
    "print_tfidf_freq(dick_corpus[0], dick_corpus, dictionary, 15, False)\n",
    "print('\\nDick Philip. Valis 15 top infrequent words with tdidf\\n')\n",
    "print_tfidf_freq(dick_corpus[1], dick_corpus, dictionary, 15, False)\n",
    "print('\\nDick Philip. A Maze of Death 15 top infrequent words with tdidf\\n')\n",
    "print_tfidf_freq(dick_corpus[2], dick_corpus, dictionary, 15, False)\n",
    "print('\\nDick Philip. Radio Free Albemuth 15 top infrequent words with tdidf\\n')\n",
    "print_tfidf_freq(dick_corpus[3], dick_corpus, dictionary, 15, False)\n",
    "print('\\nDick Philip. The Three Stigmata of Palmer Eldritch 15 top infrequent words with tdidf\\n')\n",
    "print_tfidf_freq(dick_corpus[4], dick_corpus, dictionary, 15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
